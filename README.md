
<h3 align="center">
    <img width="402" alt="awesome" src="https://user-images.githubusercontent.com/17982112/132573904-752492c6-2e23-4012-b7f8-40fcd669b61f.png">
</h3>

---
# Awesome Biologically-Motivated Learning Algorithms ðŸ§ 
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

Awesome list of research publications and media on biologically-motivated learning algorithms.

# Contents

| Publications | Media |
|:------------:|:-----:|
|[2021](https://github.com/jsalbert/awesome-biologically-motivated-learning#2021),<br />[2020](https://github.com/jsalbert/awesome-biologically-motivated-learning#2020), [2019](https://github.com/jsalbert/awesome-biologically-motivated-learning#2019), [2018](https://github.com/jsalbert/awesome-biologically-motivated-learning#2018), [2017](https://github.com/jsalbert/awesome-biologically-motivated-learning#2017), [2016](https://github.com/jsalbert/awesome-biologically-motivated-learning#2016),<br />[2015](https://github.com/jsalbert/awesome-biologically-motivated-learning#2015), [2014](https://github.com/jsalbert/awesome-biologically-motivated-learning#2014), [2012](https://github.com/jsalbert/awesome-biologically-motivated-learning#2012), [2008](https://github.com/jsalbert/awesome-biologically-motivated-learning#2008), [2003](https://github.com/jsalbert/awesome-biologically-motivated-learning#2003),<br />[1996](https://github.com/jsalbert/awesome-biologically-motivated-learning#1996), [1994](https://github.com/jsalbert/awesome-biologically-motivated-learning#1994), [1991](https://github.com/jsalbert/awesome-biologically-motivated-learning#1991), [1989](https://github.com/jsalbert/awesome-biologically-motivated-learning#1989), [1987](https://github.com/jsalbert/awesome-biologically-motivated-learning#1987)| [Podcasts](https://github.com/jsalbert/awesome-biologically-motivated-learning#podcasts) |

# Publications

## 2021

Align, then memorise: the dynamics of learning with feedback alignment [[arXiv]](https://arxiv.org/pdf/2011.12428.pdf)

Benchmarking the Accuracy and Robustness of Feedback Alignment Algorithms [[arXiv]](https://arxiv.org/abs/2108.13446)

Credit Assignment Through Broadcasting a Global Error Vector [[arXiv]](https://arxiv.org/abs/2106.04089)

Credit Assignment in Neural Networks through Deep Feedback Control [[arXiv]](https://arxiv.org/abs/2106.07887)

On the relationship between predictive coding and backpropagation [[arXiv]](https://arxiv.org/abs/2106.13082)

Predictive Coding Can Do Exact Backpropagation on Any Neural Network [[arXiv]](https://arxiv.org/abs/2103.04689)

Tourbillon: a Physically Plausible Neural Architecture [[arXiv]](https://arxiv.org/abs/2107.06424)

## 2020

A Theoretical Framework for Target Propagation [[arXiv]](https://arxiv.org/abs/2006.14331)

Backpropagation and the brain [[Nature]](https://www.nature.com/articles/s41583-020-0277-3)

Biological credit assignment through dynamic inversion of feedforward networks [[arXiv]](https://arxiv.org/abs/2007.05112)

Can the Brain Do Backpropagation? â€” Exact Implementation of Backpropagation in Predictive Coding Networks [[PDF]](https://papers.nips.cc/paper/2020/file/fec87a37cdeec1c6ecf8181c0aa2d3bf-Paper.pdf)

Contrastive Similarity Matching for Supervised Learning [[arXiv]](https://arxiv.org/abs/2002.10378)

Differentially Private Deep Learning with Direct Feedback Alignment [[arXiv]](https://arxiv.org/abs/2010.03701)

Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures [[arXiv]](https://arxiv.org/abs/2006.12878)

GAIT-prop: A biologically plausible learning rule derived from backpropagation of error [[arXiv]](https://arxiv.org/abs/2006.06438)

Identifying Learning Rules From Neural Network Observables [[arXiv]](https://arxiv.org/abs/2010.11765)

Kernelized information bottleneck leads to biologically plausible 3-factor Hebbian learning in deep networks [[arXiv]](https://arxiv.org/abs/2006.07123)

Learning to Learn with Feedback and Local Plasticity [[arXiv]](https://arxiv.org/abs/2006.09549)

Learning to solve the credit assignment problem [[arXiv]](https://arxiv.org/abs/1906.00889)

Spike-based causal inference for weight alignment [[arXiv]](https://arxiv.org/abs/1910.01689)

Two Routes to Scalable Credit Assignment without Weight Symmetry [[arXiv]](https://arxiv.org/abs/2003.01513)

## 2019

A deep learning framework for neuroscience [[Nature]](https://www.nature.com/articles/s41593-019-0520-2)

Biologically plausible deep learning -- but how far can we go with shallow networks? [[arXiv]](https://arxiv.org/abs/1905.04101) 

Deep Learning With Asymmetric Connections and Hebbian Updates [[arXiv]](https://arxiv.org/abs/1812.07965)

Deep Learning without Weight Transport [[arXiv]](https://arxiv.org/abs/1904.05391)

Direct Feedback Alignment with Sparse Connections for Local Learning [[arXiv]](https://arxiv.org/abs/1903.02083)

Efficient Convolutional Neural Network Training with Direct Feedback Alignment [[arXiv]](https://arxiv.org/abs/1901.01986)

Learning without feedback: Fixed random learning signals allow for feedforward training of deep neural networks [[arXiv]](https://arxiv.org/abs/1909.01311)

Principled Training of Neural Networks with Direct Feedback Alignment [[arXiv]](https://arxiv.org/abs/1906.04554)

Putting An End to End-to-End: Gradient-Isolated Learning of Representations [[arXiv]](https://arxiv.org/abs/1905.11786)

The HSIC Bottleneck: Deep Learning without Back-Propagation [[arXiv]](https://arxiv.org/abs/1908.01580)

Theories of Error Back-Propagation in the Brain [[PDF]](https://www.cell.com/action/showPdf?pii=S1364-6613%2819%2930012-9)

Training Neural Networks with Local Error Signals [[arXiv]](https://arxiv.org/abs/1901.06656)

## 2018

Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures [[arXiv]](https://arxiv.org/abs/1807.04587)

Biologically Motivated Algorithms for Propagating Local Target Representations [[arXiv]](https://arxiv.org/abs/1805.11703)

Biologically-plausible learning algorithms can scale to large datasets [[arXiv]](https://arxiv.org/abs/1811.03567)

Conducting Credit Assignment by Aligning Local Representations [[arXiv]](https://arxiv.org/abs/1803.01834)

Control of synaptic plasticity in deep cortical networks [[Nature]](https://www.nature.com/articles/nrn.2018.6)

Deep Supervised Learning Using Local Errors [[arXiv]](https://arxiv.org/abs/1711.06756)

Dendritic cortical microcircuits approximate the backpropagation algorithm [[arXiv]](https://arxiv.org/abs/1810.11393)

Feedback alignment in deep convolutional networks [[arXiv]](https://arxiv.org/abs/1812.06488)

Unsupervised Learning by Competing Hidden Units [[arXiv]](https://arxiv.org/abs/1806.10181)

## 2017

An Approximation of the Error Backpropagation Algorithm in a Predictive Coding Network with Local Hebbian Synaptic Plasticity [[Link]](https://pubmed.ncbi.nlm.nih.gov/28333583/)

Decoupled Neural Interfaces using Synthetic Gradients [[arXiv]](https://arxiv.org/abs/1608.05343)

Deep Learning with Dynamic Spiking Neurons and Fixed Feedback Weights [[PDF]](https://compneurojc.github.io/pdf/Deep%20Learning%20with%20Dynamic%20Spiking%20Neurons%20and%20FixedFeedback%20Weights.pdf)

Dendritic error backpropagation in deep cortical microcircuits [[arXiv]](https://arxiv.org/abs/1801.00062)

Event-Driven Random Back-Propagation: Enabling Neuromorphic Deep Learning Machines [[arXiv]](https://arxiv.org/abs/1612.05596)

Explaining the Learning Dynamics of Direct Feedback Alignment [[PDF]](https://openreview.net/pdf?id=HkXKUTVFl)

SuperSpike: Supervised learning in multi-layer spiking neural networks [[arXiv]](https://arxiv.org/abs/1705.11146)

Towards a Biologically Plausible Backprop [[arXiv]](https://arxiv.org/abs/1602.05179v3)

Towards deep learning with segregated dendrites [[arXiv]](https://arxiv.org/abs/1610.00161)

Understanding Synthetic Gradients and Decoupled Neural Interfaces [[arXiv]](https://arxiv.org/abs/1703.00522)

## 2016 

Direct Feedback Alignment Provides Learning in Deep Neural Networks [[arXiv]](https://arxiv.org/abs/1609.01596)

Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation [[arXiv]](https://arxiv.org/abs/1602.05179)

Random synaptic feedback weights support error backpropagation for deep learning [[Nature]](https://www.nature.com/articles/ncomms13276)

Toward an Integration of Deep Learning and Neuroscience [[arXiv]](https://arxiv.org/abs/1606.03813)

## 2015

How Important is Weight Symmetry in Backpropagation? [[arXiv]](https://arxiv.org/abs/1510.05067)

STDP as presynaptic activity times rate of change of postsynaptic activity [[arXiv]](https://arxiv.org/abs/1509.05936)

Towards Biologically Plausible Deep Learning [[arXiv]](https://arxiv.org/abs/1502.04156)

## 2014

Difference Target Propagation [[arXiv]](https://arxiv.org/abs/1412.7525)

How Auto-Encoders Could Provide Credit Assignment in Deep Networks via Target Propagation [[arXiv]](https://arxiv.org/abs/1407.7906)

Kickback cuts Backprop's red-tape: Biologically plausible credit assignment in neural networks [[arXiv]](https://arxiv.org/abs/1411.6191)

Random feedback weights support learning in deep neural networks [[arXiv]](https://arxiv.org/abs/1411.0247)

## 2012

Adaptive Optimal Control Without Weight Transport [[PDF]](https://watermark.silverchair.com/neco_a_00277.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAr4wggK6BgkqhkiG9w0BBwagggKrMIICpwIBADCCAqAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMAhTwO0Io9KXhBLOcAgEQgIICcUKavvKlwv8zlcG55KYDiGdamUzl_RHCUZb030s3UfsSlJmbl40pQ40L7cFtO4956duVFU9u1cGnq8ebsVVlkSSnpsrCzAshXtxCX1_BZAu_daK6bm71cT9Wrhis-T2iQ7XSv2B1kaF1j4M1RIydc0PXX90g3w96kH_v2PXXBLtsJHH59SC10-5g2B_ySCyDbNRxQ7xBh9lmuhy2DrnfgEI53sJKjXRe7gJLykj-2KwYKENZXcK2o1rwo963njrC02xQa1JcxBDJUgNfcNPqIqeUaWCJjzpjV9H_TC1bCZiGYH_nTSCZaxyjnb3iAfg_gpomeyimkwns2ifsgU_E3MWyACWEPDJ8bt2KWKUl9kh1YuHBf14gcu_ukYXUnC3UYsWfZM0hvFy8YKcpJlQwb2EJ7IuedkjJmhq9yffKl5CD5KwhklJ2OOBV5uSGOOR8KMgCqWMxdArTNIih0B7SpP1-exblmUWvfjZke44pQ4s24EwKra_4hoUFaarQ_5rpM70je7Gk1ytWbv2S9Owkbr_qBKJJ68vRYgkoP7vKCF8AZONka4Rsu0jUGgQkYVWHSKjjv7C1FSeWrN89Kq3yCmTzNsLo97jOAYjyXFcscFlJh_s4fcq6LWZ-YomAwDGqIOmx1AD1AdHa7pzM4FIOWDZReDd-KDiaQCmOH4KbLTCiAMwmSm6m2Rb4gkP5MRSiceaUvnAyGNylWD0NTI4h_0MQV1gEu5OL9BBdPjcnR0rHe1b_HVi4rLKYDaxrLqYihseNFL-H3LqJaTNWsEcMRVXOMc9SRRDxgteLIhUi5uX2FX-LcMWt_z6OTvmQXdqFxMc)

Supervised Learning in Multilayer Spiking Neural Networks [[arXiv]](https://arxiv.org/abs/1202.2249)

## 2008

Spike timing-dependent plasticity: a Hebbian learning rule [[PubMed]](https://pubmed.ncbi.nlm.nih.gov/18275283/)

## 2003

Equivalence of Backpropagation and Contrastive Hebbian Learning in a Layered Network [[PDF]](https://watermark.silverchair.com/089976603762552988.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAs4wggLKBgkqhkiG9w0BBwagggK7MIICtwIBADCCArAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM2QT60IC7IeIkWK0wAgEQgIICgdLb7UGn9W8rFcertgwM012MC8AsRaBpAQLwKIHY_PpOryehbqcGEF4Kx9juMlXMzTSnmzTsTY3lR3hAeO3HcoBYJFLQJkgmNYcIzG_06eeskow6FK-KMYM2Cz3KHYXIfxqPMP3xJyWKwfouqsTcOnXe-r163QHyCZ4QGWoP9_NIyxI8GTKbOcOERnUWeBJpIDR-W_4nu6IaMqdKNIPbyGjc4iCzW29qf2PgJAfXfwG73L5gVhtqHJSHf9TZS8LWrX4zR9iJQJWBPS21nnUlfJZU_bKSMkkKrfj6-sSMCJ3S1rbKfxTnIQVW12wSY1HpU950TB9Cd2KcNeUBR35_KvcYvLuzcaPcbvpvaUazdSBpzQtVXJB8zixOanYO-IIjY0UJpRFzT2xe5jIPSxqbyYom63_oS989511cdkZLk4ui1d5KytL_Ip8UD74pPzRPupaMe_Fzx73jLQ2BTdKx89CS0OasH0TGCN7LIac30HWSXlQI8WKVgMdzd5Lkanq4xW7Aa6IbtNCwywuXnvaruIKLdjfIVqPFjHS97fbD_8F6YkBevEVC1k4wn3mBDsW1gfdSD5CKaeu-18-w-E8UirCl6WSx3GV7LQKchVkki2u5I1SP2ThFQe_SzLZF8Bgq6uAyX6vdaKVPQ3ZhwW6QNOfm1Cp1kTVZnpmUIel7OsE3piurIgEEpdvVM3qMe1gmbRi15e7HFg6JJckp4iWOYvZ6HLJubkWxUXr4rSwsOOTc3gQjYuGNb0aBQDYz-hqorLLegZ8brj6vZJ2eLxJSHSHCJLBv2z-3-0FMDbxmZ5ccfVMv8K-g7JRgNe_-5X-uFuYHEYZavKUd6-T_IZhi8gKx)

Learning in Spiking Neural Networks by Reinforcement of Stochastic Synaptic Transmission [[PDF]](https://www.cell.com/action/showPdf?pii=S0896-6273%2803%2900761-X)

## 1996

Biologically Plausible Error-driven Learning using Local Activation Differences: The Generalized Recirculation Algorithm [[PDF]](http://psych.colorado.edu/~oreilly/papers/OReilly96_generec_nc.pdf)

## 1994

Backpropagation without weight transport [[IEEE]](https://ieeexplore.ieee.org/document/374486)

## 1991

A more biologically plausible learning rule for neural networks [[PDF]](https://www.pnas.org/content/pnas/88/10/4433.full.pdf)

## 1989

Is backpropagation biologically plausible? [[IEEE]](https://ieeexplore.ieee.org/document/118705)

## 1987

Competitive Learning: From Interactive Activation to Adaptive Resonance [[Link]](https://onlinelibrary.wiley.com/doi/10.1111/j.1551-6708.1987.tb00862.x)

Learning Representations by Recirculation [[PDF]](https://papers.nips.cc/paper/1987/file/35f4a8d465e6e1edc05f3d8ab658c551-Paper.pdf)

# Media

## Podcasts

Biologically Plausible Neural Networks - Dr. Simon Stringer [[Link]](https://youtu.be/aisgNLypUKs)

Dileep George: Brain-Inspired AI | Lex Fridman Podcast [[Link]](https://youtu.be/tg_m_LxxRwM)

Engineering a Less Artificial Intelligence with Andreas Tolias [[Link]](https://twimlai.com/twiml-talk-379-engineering-a-less-artificial-intelligence-with-andreas-tolias/)

Matt Botvinick: Neuroscience, Psychology, and AI at DeepMind | Lex Fridman Podcast [[Link]](https://youtu.be/3t06ajvBtl0)

Spiking Neural Nets and ML as a Systems Challenge with Jeff Gehlhaar [[Link]](https://twimlai.com/twiml-talk-280-spiking-neural-nets-and-ml-as-a-systems-challenge-with-jeff-gehlhaar/)

Spiking Neural Networks: A Primer with Terrence Sejnowski [[Link]](https://twimlai.com/twiml-talk-317-spiking-neural-networks-a-primer-with-dr-terrence-sejnowski/)

The Biological Path Towards Strong AI with Matthew Taylor [[Link]](https://twimlai.com/twiml-talk-71-biological-path-towards-strong-ai-matthew-taylor/)

# Contributing

[Contributing](https://github.com/jsalbert/awesome-biological-learning/blob/main/CONTRIBUTING.md)
